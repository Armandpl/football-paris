{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor 0 started\n",
      "actor 1 started\n",
      "actor 2 started\n",
      "actor 3 started\n",
      "actor 4 startedactor 5 started\n",
      "\n",
      "actor 6 started\n",
      "actor 7 started\n",
      "learner start\n",
      " data remaining. queue size :  545\n",
      " data remaining. queue size :  465\n",
      " data remaining. queue size :  385\n",
      " data remaining. queue size :  305\n",
      " data remaining. queue size :  225\n",
      " data remaining. queue size :  145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorboardX/event_file_writer.py\", line 202, in run\n",
      "    data = self._queue.get(True, queue_wait_duration)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 108, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-c82a0755af28>\", line 161, in learner\n",
      "    time.sleep(0.1)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c82a0755af28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gfootball.env as football_env\n",
    "import time, pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import torch.multiprocessing as mp \n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from FeatureEncoder import *\n",
    "from ppo import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def actor(actor_num, center_model, data_queue, signal_queue, summary_queue, arg_dict):\n",
    "    print(\"actor {} started\".format(actor_num))\n",
    "    #11_vs_11_easy_stochastic\n",
    "    #academy_empty_goal_close 300 epi done\n",
    "    #academy_empty_goal 450 epi done\n",
    "    model = PPO(arg_dict[\"lstm_size\"], arg_dict[\"k_epoch\"])\n",
    "    model.load_state_dict(center_model.state_dict())\n",
    "    fe = FeatureEncoder()\n",
    "    \n",
    "    env = football_env.create_environment(env_name=\"academy_empty_goal_close\", representation=\"raw\", stacked=False, logdir='/tmp/football', write_goal_dumps=False, write_full_episode_dumps=False, render=False)\n",
    "    n_epi = 0\n",
    "    rollout = []\n",
    "    while True:\n",
    "        env.reset()   \n",
    "        done = False\n",
    "        score = 0\n",
    "        win = 0\n",
    "        steps = 0\n",
    "        tot_reward = 0\n",
    "        n_epi += 1\n",
    "        h_out = (torch.zeros([1, 1, arg_dict[\"lstm_size\"]], dtype=torch.float), \n",
    "                 torch.zeros([1, 1, arg_dict[\"lstm_size\"]], dtype=torch.float))\n",
    "        \n",
    "        while not done:\n",
    "            t1 = time.time()\n",
    "            while signal_queue.qsize() > 0:\n",
    "                time.sleep(0.02)\n",
    "            else:\n",
    "                model.load_state_dict(center_model.state_dict())\n",
    "                \n",
    "            obs = env.observation()\n",
    "            state_dict = fe.encode(obs[0])\n",
    "            player_state = torch.from_numpy(state_dict[\"player\"]).float().unsqueeze(0).unsqueeze(0)\n",
    "            ball_state = torch.from_numpy(state_dict[\"ball\"]).float().unsqueeze(0).unsqueeze(0)\n",
    "            left_team_state = torch.from_numpy(state_dict[\"left_team\"]).float().unsqueeze(0).unsqueeze(0)\n",
    "            right_team_state = torch.from_numpy(state_dict[\"right_team\"]).float().unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            h_in = h_out\n",
    "\n",
    "            state_dict_tensor = {\n",
    "              \"player\" : player_state,\n",
    "              \"ball\" : ball_state,\n",
    "              \"left_team\" : left_team_state,\n",
    "              \"right_team\" : right_team_state,\n",
    "              \"hidden\" : h_in\n",
    "            }\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                prob, _, h_out = model(state_dict_tensor)\n",
    "            m = Categorical(prob)\n",
    "            a = m.sample().item()\n",
    "\n",
    "            prev_obs = obs\n",
    "            obs, rew, done, info = env.step(a)\n",
    "            additional_r = fe.calc_additional_reward(prev_obs[0], obs[0])\n",
    "            fin_r = rew*3.0 + additional_r\n",
    "            \n",
    "            state_prime_dict = fe.encode(obs[0])\n",
    "            \n",
    "            (h1_in, h2_in) = h_in\n",
    "            (h1_out, h2_out) = h_out\n",
    "            state_dict[\"hidden\"] = (h1_in.numpy(), h2_in.numpy())\n",
    "            state_prime_dict[\"hidden\"] = (h1_out.numpy(), h2_out.numpy())\n",
    "\n",
    "            transition = (state_dict, a, fin_r, state_prime_dict, prob[0][0][a].item(), done)\n",
    "            rollout.append(transition)\n",
    "\n",
    "            if len(rollout) == arg_dict[\"rollout_len\"]:\n",
    "                data_queue.put(rollout)\n",
    "                rollout = []\n",
    "                \n",
    "            state_dict = state_prime_dict\n",
    "\n",
    "            steps += 1\n",
    "            score += rew\n",
    "            tot_reward += fin_r\n",
    "\n",
    "            if done:\n",
    "                if score > 0:\n",
    "                    win = 1\n",
    "                summary_data = (win, score, tot_reward, steps)\n",
    "                summary_queue.put(summary_data)\n",
    "#                 if n_epi % 4 == 0 and actor_num == 0:\n",
    "#                     print(\"%d, Done, Step %d win: %d, score: %d\" % (n_epi, steps, win, score))\n",
    "#                     score = 0\n",
    "#                     win = 0\n",
    "\n",
    "\n",
    "def learner(center_model, queue, signal_queue, summary_queue, arg_dict):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = PPO(arg_dict[\"lstm_size\"], arg_dict[\"k_epoch\"], device)\n",
    "    model.load_state_dict(center_model.state_dict())\n",
    "    model.to(device)\n",
    "    cur_time = datetime.now() + timedelta(hours = 9)\n",
    "    log_dir = \"logs/\" + cur_time.strftime(\"[%m-%d]%H.%M.%S\")\n",
    "    writer = SummaryWriter(logdir=log_dir)\n",
    "    optimization_step = 0\n",
    "    n_game = 0\n",
    "    \n",
    "    print(\"learner start\")\n",
    "    \n",
    "    while True:\n",
    "        if queue.qsize() > arg_dict[\"batch_size\"]*arg_dict[\"buffer_size\"]:\n",
    "            signal_queue.put(1)\n",
    "            data = []\n",
    "            for j in range(arg_dict[\"buffer_size\"]):\n",
    "                mini_batch_np = []\n",
    "                for i in range(arg_dict[\"batch_size\"]):\n",
    "                    rollout = queue.get()\n",
    "                    mini_batch_np.append(rollout)\n",
    "                mini_batch = model.make_batch(mini_batch_np)\n",
    "                data.append(mini_batch)\n",
    "            model.train_net(data)\n",
    "            center_model.load_state_dict(model.state_dict())\n",
    "            optimization_step += arg_dict[\"batch_size\"]*arg_dict[\"buffer_size\"]*arg_dict[\"k_epoch\"]\n",
    "            \n",
    "            if queue.qsize() > arg_dict[\"batch_size\"]*arg_dict[\"buffer_size\"]:\n",
    "                print(\" data remaining. queue size : \", queue.qsize())\n",
    "            \n",
    "            \n",
    "            while summary_queue.qsize() > arg_dict[\"summary_game_window\"]:\n",
    "                win, score, tot_reward, game_len = [], [], [], []\n",
    "                \n",
    "                \n",
    "                for i in range(arg_dict[\"summary_game_window\"]):\n",
    "                    game_data = summary_queue.get()\n",
    "                    n_game += 1\n",
    "                    a,b,c,d = game_data\n",
    "                    win.append(a)\n",
    "                    score.append(b)\n",
    "                    tot_reward.append(c)\n",
    "                    game_len.append(d)\n",
    "                writer.add_scalar('game/win', float(np.mean(win)), n_game)\n",
    "                writer.add_scalar('game/score', float(np.mean(score)), n_game)\n",
    "                writer.add_scalar('game/reward', float(np.mean(tot_reward)), n_game)\n",
    "                writer.add_scalar('game/game_len', float(np.mean(game_len)), n_game)\n",
    "                writer.add_scalar('train/win', float(optimization_step), n_game)\n",
    "                \n",
    "            _ = signal_queue.get()   \n",
    "                    \n",
    "            \n",
    "        else:\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # hyperparameters\n",
    "    arg_dict = {\n",
    "        \"num_processes\": 8,\n",
    "        \"batch_size\": 16,   \n",
    "        \"buffer_size\": 5,\n",
    "        \"rollout_len\": 10,\n",
    "        \"lstm_size\" : 196,\n",
    "        \"k_epoch\" : 2,\n",
    "        \"summary_game_window\" : 5,\n",
    "    }\n",
    "    \n",
    "    np.set_printoptions(precision=3)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    torch.set_num_threads(1)\n",
    "    \n",
    "    center_model = PPO(arg_dict[\"lstm_size\"], arg_dict[\"k_epoch\"])\n",
    "    center_model.share_memory()\n",
    "    data_queue = mp.Queue()\n",
    "    signal_queue = mp.Queue()\n",
    "    summary_queue = mp.Queue()\n",
    "    processes = []\n",
    "    \n",
    "    p = mp.Process(target=learner, args=(center_model, data_queue, signal_queue, summary_queue, arg_dict))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "    for rank in range(arg_dict[\"num_processes\"]):\n",
    "        p = mp.Process(target=actor, args=(rank, center_model, data_queue, signal_queue, summary_queue, arg_dict))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "        \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10-23]20.17.21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# s= time.strftime(\"[%m-%d]%H.%M.%S\", time.gmtime())\n",
    "\n",
    "\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([False, False, False, False, False, False, False, False,  True,\n",
    "       False, True])\n",
    "\n",
    "print(np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
